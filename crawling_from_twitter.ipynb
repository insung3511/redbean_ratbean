{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/data_train.csv\",encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'sadness' 'fear' 'anger' 'joy']\n"
     ]
    }
   ],
   "source": [
    "print(data['Emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = copy.deepcopy(data)\n",
    "\n",
    "netral_data = data_[data_.Emotion=='neutral']\n",
    "sadness_data = data_[data_.Emotion=='sadness']\n",
    "fear_data = data_[data_.Emotion=='fear']\n",
    "anger_data = data_[data_.Emotion=='anger']\n",
    "joy_data = data_[data_.Emotion=='joy']\n",
    "\n",
    "sub_data = pd.concat([netral_data, sadness_data, fear_data, anger_data, joy_data], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target=data.groupby('Emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness    1641\n",
       "joy        1619\n",
       "neutral    1616\n",
       "anger      1566\n",
       "fear       1492\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date\n",
    "\n",
    "At what time do people like to tweet? Is there a clear link between the time of tweeting and the emotion of the content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words\n",
    "\n",
    "Words distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bahk_insung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netural data shape : (1616, 2)\n",
      "sadness data shape : (1641, 2)\n",
      "feat data shape : (1492, 2)\n",
      "anger data shape : (1566, 2)\n",
      "joy data shape : (1619, 2)\n",
      "(7934, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Yes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Perhaps we need to have more babies ! Tina ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Over there .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion                                               Text\n",
       "0   neutral   There are tons of other paintings that I thin...\n",
       "8   neutral                                             Yes . \n",
       "14  neutral   Perhaps we need to have more babies ! Tina ga...\n",
       "15  neutral                                             Why ? \n",
       "23  neutral                                      Over there . "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netral_data = data_[data_.Emotion=='neutral']\n",
    "print(f\"netural data shape : {netral_data.shape}\")\n",
    "\n",
    "sadness_data = data_[data_.Emotion=='sadness']\n",
    "print(f\"sadness data shape : {sadness_data.shape}\")\n",
    "\n",
    "fear_data = data_[data_.Emotion=='fear']\n",
    "print(f\"feat data shape : {fear_data.shape}\")\n",
    "\n",
    "anger_data = data_[data_.Emotion=='anger']\n",
    "print(f\"anger data shape : {anger_data.shape}\")\n",
    "\n",
    "joy_data = data_[data_.Emotion=='joy']\n",
    "print(f\"joy data shape : {joy_data.shape}\")\n",
    "\n",
    "emo_data = pd.concat([netral_data, sadness_data, fear_data, anger_data, joy_data], axis=0)\n",
    "print(data.shape)\n",
    "\n",
    "emo_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/training.1600000.processed.noemoticon.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"TweetText\"]\n",
    "data.columns = DATASET_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = copy.deepcopy(data)\n",
    "\n",
    "positif_data = data_[data_.target==4].iloc[:80000,:]\n",
    "netural_data = data_[data_.target==2].iloc[:80000, :]\n",
    "negative_data = data_[data_.target==0].iloc[:80000,:]\n",
    "\n",
    "sub_data = pd.concat([positif_data, netural_data, negative_data],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target=data.groupby('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date\n",
    "\n",
    "At what time do people like to tweet? Is there a clear link between the time of tweeting and the emotion of the content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                           TweetText  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                          date\n",
       "0       0  Mon Apr 06 22:19:49 PDT 2009\n",
       "1       0  Mon Apr 06 22:19:53 PDT 2009\n",
       "2       0  Mon Apr 06 22:19:57 PDT 2009\n",
       "3       0  Mon Apr 06 22:19:57 PDT 2009\n",
       "4       0  Mon Apr 06 22:20:00 PDT 2009"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = {'target': data['target'], 'date': data['date']}\n",
    "df = pd.DataFrame(data_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "# lets ensure the 'date' column is in date format\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:53</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:20:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                date  hour\n",
       "0       0 2009-04-06 22:19:49    22\n",
       "1       0 2009-04-06 22:19:53    22\n",
       "2       0 2009-04-06 22:19:57    22\n",
       "3       0 2009-04-06 22:19:57    22\n",
       "4       0 2009-04-06 22:20:00    22"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour = [ df['date'][i].hour for i in range(len(df['date'])) ]\n",
    "df['hour'] = hour\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_data = {'0': [0]*24, '2': [0]*24, '4': [0]*24}\n",
    "for i in range(len(df['hour'])):\n",
    "    target = str(df['target'][i])\n",
    "    hour = int(df['hour'][i])\n",
    "    hour_data[target][hour] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_data = [hour_data['0'], hour_data['2'], hour_data['4']]\n",
    "# Transpose\n",
    "hour_data = list(map(list,zip(*hour_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words\n",
    "\n",
    "Words distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = copy.deepcopy(sub_data)\n",
    "newdata.drop(['ids','date','flag','user'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bahk_insung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 6)\n",
      "(799999, 6)\n",
      "(1599999, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822272</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ersle</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822273</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>becca210</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822283</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Wingman29</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822287</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>katarinka</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822293</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_EmilyYoung</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "799999       4  1467822272  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "800000       4  1467822273  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "800001       4  1467822283  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "800002       4  1467822287  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "800003       4  1467822293  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                          TweetText  \n",
       "799999        ersle       I LOVE @Health4UandPets u guys r the best!!   \n",
       "800000     becca210  im meeting up with one of my besties tonight! ...  \n",
       "800001    Wingman29  @DaRealSunisaKim Thanks for the Twitter add, S...  \n",
       "800002    katarinka  Being sick can be really cheap when it hurts t...  \n",
       "800003  _EmilyYoung    @LovesBrooklyn2 he has that effect on everyone   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positif_data = data[data.target==4]\n",
    "print(positif_data.shape)\n",
    "\n",
    "negative_data = data[data.target==0]\n",
    "print(negative_data.shape)\n",
    "\n",
    "deep_data = pd.concat([positif_data,negative_data],axis = 0)\n",
    "print(data.shape)\n",
    "\n",
    "deep_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_64380/1406119821.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['Clean_TweetText'] = data['Clean_TweetText'].str.replace(r\"http\\S+\", \"\")\n",
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_64380/1406119821.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['Clean_TweetText'] = data['Clean_TweetText'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "data['Clean_TweetText'] = data['TweetText'].str.replace(\"@\", \"\") \n",
    "data['Clean_TweetText'] = data['Clean_TweetText'].str.replace(r\"http\\S+\", \"\") \n",
    "data['Clean_TweetText'] = data['Clean_TweetText'].str.replace(\"[^a-zA-Z]\", \" \") \n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    clean_text=' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Clean_TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many times ball managed save re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>kwesidei whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                           TweetText  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3  @nationwideclass no, it's not behaving at all....   \n",
       "4                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                     Clean_TweetText  \n",
       "0  upset update facebook texting might cry result...  \n",
       "1  kenichan dived many times ball managed save re...  \n",
       "2                   whole body feels itchy like fire  \n",
       "3                   nationwideclass behaving mad see  \n",
       "4                                kwesidei whole crew  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clean_TweetText'] = data['Clean_TweetText'].apply(lambda text : remove_stopwords(text.lower()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Clean_TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[upset, update, facebook, texting, might, cry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[nationwideclass, behaving, mad, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[kwesidei, whole, crew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                           TweetText  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3  @nationwideclass no, it's not behaving at all....   \n",
       "4                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                     Clean_TweetText  \n",
       "0  [upset, update, facebook, texting, might, cry,...  \n",
       "1  [kenichan, dived, many, times, ball, managed, ...  \n",
       "2            [whole, body, feels, itchy, like, fire]  \n",
       "3              [nationwideclass, behaving, mad, see]  \n",
       "4                            [kwesidei, whole, crew]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Tokenization and Normalization\n",
    "data['Clean_TweetText'] = data['Clean_TweetText'].apply(lambda x: word_tokenize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Clean_TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset update facebook texting might result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many times ball managed save re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>kwesidei whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                           TweetText  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3  @nationwideclass no, it's not behaving at all....   \n",
       "4                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                     Clean_TweetText  \n",
       "0  upset update facebook texting might result sch...  \n",
       "1  kenichan dived many times ball managed save re...  \n",
       "2                   whole body feels itchy like fire  \n",
       "3                           nationwideclass behaving  \n",
       "4                                kwesidei whole crew  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let’s stitch these tokens back together\n",
    "data['Clean_TweetText'] = data['Clean_TweetText'].apply(lambda x: ' '.join([w for w in x]))\n",
    "# Removing small words\n",
    "data['Clean_TweetText'] = data['Clean_TweetText'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7934, 9887)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "emo_cv = count_vectorizer.fit_transform(emo_data['Text'])\n",
    "print(emo_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9887)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "undersampler_ratio = {\n",
    "    \"neutral\" : 1000,\n",
    "    \"joy\" : 1000,\n",
    "    \"sadness\" : 1000,\n",
    "    \"anger\" : 1000,\n",
    "    \"fear\" : 1000\n",
    "}\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=undersampler_ratio)\n",
    "emo_X, emo_y = rus.fit_resample(emo_cv, emo_data['Emotion'])\n",
    "\n",
    "print(emo_X.shape)\n",
    "print(emo_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'sadness' 'fear' 'anger' 'joy']\n"
     ]
    }
   ],
   "source": [
    "print(emo_data['Emotion'].unique())\n",
    "\n",
    "onehot_label = list()\n",
    "for value in emo_y:\n",
    "    if value == \"neutral\":\n",
    "        onehot_label.append([1, 0, 0, 0, 0])\n",
    "\n",
    "    elif value == \"sadness\":\n",
    "        onehot_label.append([0, 1, 0, 0, 0])\n",
    "\n",
    "    elif value == \"fear\":\n",
    "        onehot_label.append([0, 0, 1, 0, 0])\n",
    "\n",
    "    elif value == \"anger\":\n",
    "        onehot_label.append([0, 0, 0, 1, 0])\n",
    "\n",
    "    elif value == \"joy\":\n",
    "        onehot_label.append([0, 0, 0, 0, 1])\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "onehot_label = np.array(onehot_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape : (3350, 9887)\n",
      "y_train shape : (3350, 5)\n",
      "\n",
      "X_test shape : (1650, 9887)\n",
      "y_test shape : (1650, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emo_X = emo_X.toarray()\n",
    "\n",
    "emo_X_train, emo_X_test, emo_y_train, emo_y_test = train_test_split(emo_X, onehot_label, test_size=.33, random_state=42)\n",
    "print(f'''\n",
    "X_train shape : {emo_X_train.shape}\n",
    "y_train shape : {emo_y_train.shape}\n",
    "\n",
    "X_test shape : {emo_X_test.shape}\n",
    "y_test shape : {emo_y_test.shape}\n",
    "''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepression y onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 546404)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "deep_cv = count_vectorizer.fit_transform(data['Clean_TweetText'])\n",
    "deep_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 546404)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "undersampler_ratio = {\n",
    "    0 : 2500,\n",
    "    4 : 2500\n",
    "}\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=undersampler_ratio)\n",
    "deep_X, deep_y = rus.fit_resample(deep_cv, data['target'])\n",
    "\n",
    "print(deep_X.shape)\n",
    "print(deep_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "deep_y_onehot = list()\n",
    "for value in deep_y:\n",
    "    if value == 0:\n",
    "        deep_y_onehot.append([1, 0])\n",
    "\n",
    "    elif value == 4:\n",
    "        deep_y_onehot.append([0, 1])\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "deep_y_onehot = np.array(deep_y_onehot)\n",
    "print(deep_y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape : (3350, 546404)\n",
      "y_train shape : (3350, 2)\n",
      "\n",
      "X_test shape : (1650, 546404)\n",
      "y_test shape : (1650, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deep_X = deep_X.toarray()\n",
    "\n",
    "deep_X_train, deep_X_test, deep_y_train, deep_y_test = train_test_split(deep_X, deep_y_onehot, test_size=.33, random_state=42)\n",
    "print(f'''\n",
    "X_train shape : {deep_X_train.shape}\n",
    "y_train shape : {deep_y_train.shape}\n",
    "\n",
    "X_test shape : {deep_X_test.shape}\n",
    "y_test shape : {deep_y_test.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_input_layer = layers.Input(shape=(1, 9887), name=\"emotion_model_input\")\n",
    "x1 = layers.Conv1D(2048, 3, padding='same', activation='relu')(emo_input_layer)\n",
    "x1 = layers.Embedding(2048, 1024)(x1)\n",
    "x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "x1 = layers.Reshape((1, 1024))(x1)\n",
    "\n",
    "x1 = layers.Conv1D(1024, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.Conv1D(1024, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "\n",
    "x1 = layers.Conv1D(256, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.Conv1D(256, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "temp_x1 = layers.Flatten()(x1)\n",
    "temp_emo_y = layers.Dense(5, activation='softmax', name=\"Before_GRU_emo\")(temp_x1)\n",
    "\n",
    "x1 = layers.Reshape((1, 256))(x1)\n",
    "x1 = layers.GRU(256)(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "\n",
    "x1 = layers.Flatten()(x1)\n",
    "x1 = layers.Dense(50)(x1)\n",
    "x1 = layers.Dense(30)(x1)\n",
    "x1 = layers.Dense(15)(x1)\n",
    "emo_y = layers.Dense(5, activation='softmax', name=\"final\")(x1)\n",
    "emo_model = Model(inputs=emo_input_layer, outputs=[emo_y, temp_emo_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " emotion_model_input (InputLaye  [(None, 1, 9887)]   0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 1, 2048)      60747776    ['emotion_model_input[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)       (None, 1, 2048, 102  2097152     ['conv1d_38[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 1024)        0           ['embedding_18[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1024)      0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 1, 1024)      3146752     ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 1, 1024)      3146752     ['conv1d_39[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 1, 1024)     4096        ['conv1d_40[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 1, 1024)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 1, 512)       1573376     ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 1, 512)       786944      ['conv1d_41[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 1, 512)      2048        ['conv1d_42[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 1, 512)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1, 512)       0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 1, 512)       786944      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 1, 512)       786944      ['conv1d_43[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 512)      2048        ['conv1d_44[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 1, 512)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 1, 256)       393472      ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 1, 256)       196864      ['conv1d_45[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1, 256)      1024        ['conv1d_46[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 1, 256)      0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 256)       0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " gru_4 (GRU)                    (None, 256)          394752      ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['gru_4[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 256)          0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50)           12850       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30)           1530        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 15)           465         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 256)          0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " final (Dense)                  (None, 5)            80          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " Before_GRU_emo (Dense)         (None, 5)            1285        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 74,083,154\n",
      "Trainable params: 74,078,546\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_input_layer = layers.Input(shape=(1, 546404), name=\"deep_model_input\")\n",
    "# x = layers.Conv1D(2048, 3, padding='same', activation='relu')(deep_input_layer)\n",
    "\n",
    "# x = layers.Conv1D(1024, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(1024, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "\n",
    "# x = layers.Conv1D(1024, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(1024, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "\n",
    "# x = layers.Conv1D(512, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(512, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "\n",
    "# x = layers.Conv1D(512, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(512, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "\n",
    "# x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "\n",
    "# x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x)\n",
    "# temp_deep_y = layers.Dense(2, activation='softmax', name=\"Before_GRU_deep\")(x)\n",
    "\n",
    "# x = layers.Reshape((1, 256))(x)\n",
    "# x = layers.GRU(256)(x)\n",
    "\n",
    "# x = layers.Reshape((4, 64))(x)\n",
    "# x = layers.GRU(64)(x)\n",
    "\n",
    "# x = layers.Dense(50)(x)\n",
    "# x = layers.Dense(30)(x)\n",
    "# x = layers.Dense(15)(x)\n",
    "# deep_y = layers.Dense(2, activation='softmax')(x)\n",
    "# deep_model = Model(inputs=deep_input_layer, outputs=[deep_y, temp_deep_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model = Model(inputs=[deep_input_layer, emo_input_layer], outputs=[temp_deep_y, deep_y, temp_emo_y, emo_y])\n",
    "# combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.Adam(\n",
    "    lr=0.003\n",
    ")\n",
    "\n",
    "emo_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "plot_model(emo_model, show_shapes=True, to_file='model_visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/' \n",
    "model_names = outDir + 'weights-{val_final_accuracy:.4f}.h5'\n",
    "def get_callbacks(patience = 50):\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_final_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "    callbacks = [model_checkpoint]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_X_train = emo_X_train.reshape(-1, 1, 9887)\n",
    "emo_X_test = emo_X_test.reshape(-1, 1, 9887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1650, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_X_test.shape\n",
    "emo_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_38/kernel:0', 'conv1d_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_38/kernel:0', 'conv1d_38/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 21:01:39.769053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-29 21:01:40.614371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-29 21:01:41.456652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - ETA: 0s - loss: 3.2232 - final_loss: 1.6126 - Before_GRU_emo_loss: 1.6106 - final_accuracy: 0.1830 - Before_GRU_emo_accuracy: 0.1967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 21:02:14.433988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-29 21:02:14.783993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_final_accuracy improved from -inf to 0.19818, saving model to ./cheakpoint/weights-0.1982.h5\n",
      "27/27 [==============================] - 51s 2s/step - loss: 3.2232 - final_loss: 1.6126 - Before_GRU_emo_loss: 1.6106 - final_accuracy: 0.1830 - Before_GRU_emo_accuracy: 0.1967 - val_loss: 3.2206 - val_final_loss: 1.6108 - val_Before_GRU_emo_loss: 1.6098 - val_final_accuracy: 0.1982 - val_Before_GRU_emo_accuracy: 0.1909\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 3.2901 - final_loss: 1.6273 - Before_GRU_emo_loss: 1.6628 - final_accuracy: 0.2009 - Before_GRU_emo_accuracy: 0.2015\n",
      "Epoch 2: val_final_accuracy improved from 0.19818 to 0.20727, saving model to ./cheakpoint/weights-0.2073.h5\n",
      "27/27 [==============================] - 80s 3s/step - loss: 3.2901 - final_loss: 1.6273 - Before_GRU_emo_loss: 1.6628 - final_accuracy: 0.2009 - Before_GRU_emo_accuracy: 0.2015 - val_loss: 3.2194 - val_final_loss: 1.6093 - val_Before_GRU_emo_loss: 1.6101 - val_final_accuracy: 0.2073 - val_Before_GRU_emo_accuracy: 0.1970\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 3.2617 - final_loss: 1.6236 - Before_GRU_emo_loss: 1.6380 - final_accuracy: 0.1896 - Before_GRU_emo_accuracy: 0.1824\n",
      "Epoch 3: val_final_accuracy did not improve from 0.20727\n",
      "27/27 [==============================] - 84s 3s/step - loss: 3.2617 - final_loss: 1.6236 - Before_GRU_emo_loss: 1.6380 - final_accuracy: 0.1896 - Before_GRU_emo_accuracy: 0.1824 - val_loss: 3.2208 - val_final_loss: 1.6103 - val_Before_GRU_emo_loss: 1.6104 - val_final_accuracy: 0.1909 - val_Before_GRU_emo_accuracy: 0.1909\n",
      "Epoch 4/100\n",
      "14/27 [==============>...............] - ETA: 29s - loss: 3.2448 - final_loss: 1.6204 - Before_GRU_emo_loss: 1.6244 - final_accuracy: 0.1970 - Before_GRU_emo_accuracy: 0.2009"
     ]
    }
   ],
   "source": [
    "callbacks = get_callbacks()\n",
    "\n",
    "history = emo_model.fit(\n",
    "    emo_X_train, emo_y_train,\n",
    "    shuffle=True,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_data=(emo_X_test, emo_y_test),\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(history)\n",
    "loss,acc = emo_model.evaluate(emo_X_test, emo_y_test, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tesnorflow import keras\n",
    "\n",
    "model_path = './checkpoint/'\n",
    "model_path = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "recon_model = keras.models.load_model(model_path)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbd03b52000256fffc5622fb1d5afa03ae770321afbfaac74e08013d54c137c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
