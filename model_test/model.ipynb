{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a3c9c4d2-ff55-4324-ae4d-12c4476ee128",
    "_kg_hide-output": true,
    "_uuid": "d7c7da22-b8b3-4191-a016-ee3545b1fcc8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellbeing = pd.read_csv('./data/Wellbeing_and_lifestyle_data_Kaggle.csv')\n",
    "wellbeing = wellbeing.drop('Timestamp', axis=1)\n",
    "wellbeing = wellbeing.drop([10005]) \n",
    "\n",
    "age_dict = {'Less than 20' : 1, '21 to 35' : 2, '36 to 50' : 3, '51 or more' : 4}\n",
    "wellbeing['AGE'] = pd.Series([age_dict[x] for x in wellbeing.AGE], index=wellbeing.index)\n",
    "\n",
    "gender_dict = {'Female' : 1, 'Male' : 0}\n",
    "wellbeing['GENDER'] = pd.Series([gender_dict[x] for x in wellbeing.GENDER], index=wellbeing.index)\n",
    "\n",
    "wellbeing['DAILY_STRESS'] = wellbeing['DAILY_STRESS'].astype(int)\n",
    "\n",
    "X = wellbeing.drop(['DAILY_STRESS', 'ACHIEVEMENT'], axis=1)\n",
    "y = wellbeing[['DAILY_STRESS', 'ACHIEVEMENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 43, test_size=0.33)\n",
    "# print(f'''\n",
    "# Train X shape : {train_X.shape}\n",
    "# Train y shape : {train_y.shape}\n",
    "\n",
    "# Test X shape : {val_X.shape}\n",
    "# Test y shape : {val_y.shape}\n",
    "# ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Anayslsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y['ACHIEVEMENT'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y['DAILY_STRESS'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_achievement_cate = list()\n",
    "for value in tqdm(y['ACHIEVEMENT']):\n",
    "    if value < 2:\n",
    "        y_achievement_cate.append([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "    elif 2 <= value and value < 4:\n",
    "        y_achievement_cate.append([0, 1, 0, 0, 0, 0])\n",
    "\n",
    "    elif 4 <= value and value < 6:\n",
    "        y_achievement_cate.append([0, 0, 1, 0, 0, 0])\n",
    "\n",
    "    elif 6 <= value and value < 8:\n",
    "        y_achievement_cate.append([0, 0, 0, 1, 0, 0])\n",
    "\n",
    "    elif 8 <= value and value < 10:\n",
    "        y_achievement_cate.append([0, 0, 0, 0, 1, 0])\n",
    "\n",
    "    else:\n",
    "        y_achievement_cate.append([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "y_achievement_cate = np.array(y_achievement_cate)\n",
    "print(f\"y_achievement category array shape : {y_achievement_cate.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_daily_stress_cate = list()\n",
    "\n",
    "for value in tqdm(y['DAILY_STRESS']):\n",
    "    if value == 0:\n",
    "        y_daily_stress_cate.append([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "    elif value == 1:\n",
    "        y_daily_stress_cate.append([0, 1, 0, 0, 0, 0])\n",
    "\n",
    "    elif value == 2:\n",
    "        y_daily_stress_cate.append([0, 0, 1, 0, 0, 0])\n",
    "\n",
    "    elif value == 3:\n",
    "        y_daily_stress_cate.append([0, 0, 0, 1, 0, 0])\n",
    "\n",
    "    elif value == 4:\n",
    "        y_daily_stress_cate.append([0, 0, 0, 0, 1, 0])\n",
    "\n",
    "    else:\n",
    "        y_daily_stress_cate.append([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "y_daily_stress_cate = np.array(y_daily_stress_cate)\n",
    "print(f\"y_daily_stress_category shape : {y_daily_stress_cate.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y_daily_stress_cate, random_state = 42, test_size=0.33)\n",
    "print(f'''\n",
    "Train X shape : {train_X.shape}\n",
    "Train y shape : {train_y.shape}\n",
    "\n",
    "Test X shape : {val_X.shape}\n",
    "Test y shape : {val_y.shape}\n",
    "''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefms = keras.Sequential([\n",
    "    layers.Conv1D(32, 3, padding='same', input_shape=(21, 1)),\n",
    "    layers.Activation(keras.activations.relu),\n",
    "    \n",
    "    layers.Conv1D(64, 3, padding='same'),\n",
    "    layers.Conv1D(64, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(keras.activations.relu),\n",
    "    layers.MaxPool1D(pool_size=(2), strides=2),\n",
    "   \n",
    "    layers.Conv1D(64, 3, padding='same'),\n",
    "    layers.Conv1D(64, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(keras.activations.relu),\n",
    "    layers.MaxPool1D(pool_size=(2), strides=2),\n",
    "    layers.Dropout(0.5), \n",
    "\n",
    "    layers.Conv1D(32, 3, padding='same'),\n",
    "    layers.Conv1D(32, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(keras.activations.relu),\n",
    "    layers.MaxPool1D(pool_size=(2), strides=2),\n",
    "     \n",
    "    layers.Conv1D(16, 3, padding='same'),\n",
    "    layers.Conv1D(16, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(keras.activations.relu),\n",
    "\n",
    "    layers.Reshape((1, 32)),\n",
    "    layers.GRU(32),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(6, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(\n",
    "        learning_rate=0.003\n",
    ")\n",
    "\n",
    "lefms.compile(\n",
    "        optimizer=adam,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lefms.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = './cheakpoint/lefms_model/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{val_accuracy:.4f}.h5'\n",
    "def get_callbacks(patience = 50):\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=patience)\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "  \n",
    "    # callbacks = [earlystop, model_checkpoint]     # earlystop 사용하고 싶으면 이거 풀고 아래꺼 주석 처리\n",
    "    callbacks = [model_checkpoint]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks()\n",
    "model_history = lefms.fit(\n",
    "    train_X, train_y,\n",
    "    batch_size=64,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(val_X, val_y),\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(model_history)\n",
    "loss,acc = lefms.evaluate(val_X, val_y, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall models, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved_path = './cheakpoint/lefms_model/'\n",
    "\n",
    "recall_model_path = model_saved_path + sorted(os.listdir(model_saved_path))[-1]\n",
    "reconstructed_model = keras.models.load_model(recall_model_path)\n",
    "print(f\"Recalled model path : {recall_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reconstructed_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbd03b52000256fffc5622fb1d5afa03ae770321afbfaac74e08013d54c137c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
