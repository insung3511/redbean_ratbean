{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sending solidarity whoever doctor manage incre...</td>\n",
       "      <td>Stressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need see hair amp beard gat book appointment b...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next time meet someone new dont ask ask love</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise someone love give la senza gift box r...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raise hand junhoes ocean lotion life rent free...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets    labels\n",
       "0  sending solidarity whoever doctor manage incre...  Stressed\n",
       "1  need see hair amp beard gat book appointment b...   Anxious\n",
       "2      next time meet someone new dont ask ask love     Normal\n",
       "3  surprise someone love give la senza gift box r...    Lonely\n",
       "4  raise hand junhoes ocean lotion life rent free...    Normal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\",encoding='latin-1')\n",
    "data = data.iloc[:20000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stressed' 'Anxious' 'Normal' 'Lonely']\n"
     ]
    }
   ],
   "source": [
    "print(data['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = copy.deepcopy(data)\n",
    "\n",
    "stressed_data = data_[data_.labels=='Stressed']\n",
    "anxious_data  = data_[data_.labels=='Anxious']\n",
    "normal_data   = data_[data_.labels=='Normal']\n",
    "lonely_data   = data_[data_.labels=='Lonely']\n",
    "sub_data = pd.concat([stressed_data, anxious_data, normal_data, lonely_data],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target=data.groupby('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anxious     5502\n",
       "Normal      5355\n",
       "Lonely      4604\n",
       "Stressed    4539\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words\n",
    "\n",
    "Words distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bahk_insung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 18296)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "cv = count_vectorizer.fit_transform(data['tweets'])\n",
    "cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stressed' 'Anxious' 'Normal' 'Lonely']\n"
     ]
    }
   ],
   "source": [
    "print(data['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n"
     ]
    }
   ],
   "source": [
    "y_label_onehot = list()\n",
    "\n",
    "for value in data['labels']:\n",
    "    if value == \"Stressed\":\n",
    "        y_label_onehot.append([1, 0, 0, 0])\n",
    "\n",
    "    elif value == \"Anxious\":\n",
    "        y_label_onehot.append([0, 1, 0, 0])\n",
    "\n",
    "    elif value == \"Normal\":\n",
    "        y_label_onehot.append([0, 0, 1, 0])\n",
    "\n",
    "    elif value == \"Lonely\":\n",
    "        y_label_onehot.append([0, 0, 0, 1])\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "X = cv.toarray()\n",
    "y_label_onehot = np.array(y_label_onehot)\n",
    "print(y_label_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape : (16000, 1, 18296)\n",
      "y_train shape : (16000, 4)\n",
      "\n",
      "X_test shape : (4000, 1, 18296)\n",
      "y_test shape : (4000, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(-1, 1, 18296)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_label_onehot, test_size=.2, random_state=42)\n",
    "print(f'''\n",
    "X_train shape : {X_train.shape}\n",
    "y_train shape : {y_train.shape}\n",
    "\n",
    "X_test shape : {X_test.shape}\n",
    "y_test shape : {y_test.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Reshape.__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m emo_input_layer \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m18296\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39memotion_model_input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m gru_x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mGRU(\u001b[39m9000\u001b[39m)(emo_input_layer)\n\u001b[0;32m----> 4\u001b[0m gru_x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mReshape(\u001b[39m1\u001b[39;49m, \u001b[39m9000\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m gru_x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mConv1D(\u001b[39m4096\u001b[39m, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(gru_x)\n\u001b[1;32m      6\u001b[0m gru_x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mConv1D(\u001b[39m4096\u001b[39m, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(gru_x)\n",
      "\u001b[0;31mTypeError\u001b[0m: Reshape.__init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "emo_input_layer = layers.Input(shape=(1, 18296), name=\"emotion_model_input\")\n",
    "\n",
    "gru_x = layers.GRU(9000)(emo_input_layer)\n",
    "gru_x = layers.Reshape(1, 9000)\n",
    "gru_x = layers.Conv1D(4096, 3, padding='same', activation='relu')(gru_x)\n",
    "gru_x = layers.Conv1D(4096, 3, padding='same', activation='relu')(gru_x)\n",
    "gru_x = layers.BatchNormalization()(gru_x)\n",
    "gru_x = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(gru_x)\n",
    "\n",
    "x1 = layers.Conv1D(1024, 3, padding='same', activation='relu')(emo_input_layer)\n",
    "x1 = layers.Conv1D(1024, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x1)\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "# temp_x1 = layers.Flatten()(x1)\n",
    "# temp_emo_y = layers.Dense(4, activation='softmax', name=\"Before_GRU_emo\")(temp_x1)\n",
    "\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.Conv1D(512, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "\n",
    "x1 = layers.Concatenate()([gru_x, x1])\n",
    "\n",
    "x1 = layers.Conv1D(256, 3, padding='same', activation='relu',  kernel_regularizer=tf.keras.regularizers.L2(0.01))(x1)\n",
    "x1 = layers.Conv1D(256, 3, padding='same', activation='relu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPool1D(pool_size=(2), strides=2, padding='same')(x1)\n",
    "x1 = layers.Reshape((1, 256))(x1)\n",
    "x1 = layers.GRU(256)(x1)\n",
    "x1 = layers.Dropout(0.7)(x1)\n",
    "\n",
    "x1 = layers.Flatten()(x1)\n",
    "x1 = layers.Dense(50)(x1)\n",
    "x1 = layers.Dense(30)(x1)\n",
    "x1 = layers.Dense(15)(x1)\n",
    "emo_y = layers.Dense(4, activation='softmax', name=\"final\")(x1)\n",
    "model = Model(inputs=emo_input_layer, outputs=[emo_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.optimizers.Adam(\n",
    "    lr = 0.003\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/' \n",
    "model_names = outDir + 'weights-{val_final_accuracy:.4f}.h5'\n",
    "def get_callbacks(patience = 50):\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_final_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "    callbacks = [model_checkpoint]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    shuffle=True,\n",
    "    batch_size=20,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbd03b52000256fffc5622fb1d5afa03ae770321afbfaac74e08013d54c137c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
